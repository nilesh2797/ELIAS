{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/disk2/nileshgupta/ELIAS\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/disks/disk2/nileshgupta/ELIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nileshgupta_google_com/.conda/envs/xc/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os, time, socket, yaml, wandb, logging\n",
    "import logging.config\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nets import *\n",
    "from losses import *\n",
    "from optimizer_bundles import *\n",
    "from resources import _c, load_config_and_runtime_args, dump_diff_config, get_free_gpu\n",
    "from datasets import DATA_MANAGERS, XMCEvaluator, XMCDataManager\n",
    "from dl_helper import unwrap\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "transformers.set_seed(42)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_config_and_runtime_args(f'python Results/ELIAS-new/amazon-670k/ELIAS-2/config.yaml'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mat = sp.load_npz(f'Results/ELIAS-new/amazon-670k/ELIAS-2/tst_score_mat.npz')\n",
    "ranker_score_mat = sp.load_npz(f'Results/ELIAS-new/amazon-670k/ELIAS-2/tst_ranker_score_mat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = DATA_MANAGERS['xmc'](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader, val_loader, tst_loader = data_manager.build_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Adapted sorted_csr from https://github.com/amzn/pecos/blob/f73537aa7e963eedce1373fbb4184143e2381e6d/pecos/utils/smat_util.py#L256\n",
    "def sorted_csr_from_coo(shape, row_idx, col_idx, val, only_topk=None, replace_val_with_rank=False):\n",
    "    csr = sp.csr_matrix((val, (row_idx, col_idx)), shape=shape)\n",
    "    csr.sort_indices()\n",
    "    for i in range(shape[0]):\n",
    "        rng = slice(csr.indptr[i], csr.indptr[i + 1])\n",
    "        sorted_idx = np.argsort(-csr.data[rng], kind=\"mergesort\")\n",
    "        csr.indices[rng] = csr.indices[rng][sorted_idx]\n",
    "        csr.data[rng] = csr.data[rng][sorted_idx]\n",
    "\n",
    "    if only_topk is not None:\n",
    "        assert isinstance(only_topk, int), f\"Wrong type: type(only_topk) = {type(only_topk)}\"\n",
    "        only_topk = max(min(1, only_topk), only_topk)\n",
    "        nnz_of_insts = csr.indptr[1:] - csr.indptr[:-1]\n",
    "        row_idx = np.repeat(np.arange(shape[0], dtype=csr.indices.dtype), nnz_of_insts)\n",
    "        selected_idx = (np.arange(len(csr.data)) - csr.indptr[row_idx]) < only_topk\n",
    "        row_idx = row_idx[selected_idx]\n",
    "        col_idx = csr.indices[selected_idx]\n",
    "        val = csr.data[selected_idx]\n",
    "        indptr = np.cumsum(np.bincount(row_idx + 1, minlength=(shape[0] + 1)))\n",
    "        csr = sp.csr_matrix((val, col_idx, indptr), shape=shape, dtype=val.dtype)\n",
    "\n",
    "    if replace_val_with_rank:\n",
    "        csr.data = np.concatenate([np.arange(x)+1 for x in csr.getnnz(1)])\n",
    "        \n",
    "    return csr\n",
    "\n",
    "def sorted_csr(csr, only_topk=None, replace_val_with_rank=False):\n",
    "    if not isinstance(csr, sp.csr_matrix):\n",
    "        raise ValueError(\"the input matrix must be a csr_matrix.\")\n",
    "\n",
    "    row_idx = np.repeat(np.arange(csr.shape[0], dtype=np.uint32), csr.indptr[1:] - csr.indptr[:-1])\n",
    "    return sorted_csr_from_coo(csr.shape, row_idx, csr.indices, csr.data, only_topk, replace_val_with_rank)\n",
    "\n",
    "def compute_precision_recall(score_mat, true_mat, pK=[1,3,5], rK=[10,20,50,100]):\n",
    "    allK = list(set([*pK, *rK]))\n",
    "    maxK = max(allK)\n",
    "    bin_true_mat = true_mat.copy()\n",
    "    bin_true_mat.data[:] = 1.0\n",
    "    rank_score_mat = sorted_csr(score_mat, only_topk=maxK, replace_val_with_rank=True)\n",
    "    metrics = {}\n",
    "    for k in sorted(allK, reverse=True):\n",
    "        rank_score_mat.data[rank_score_mat.data > k] = 0\n",
    "        rank_score_mat.eliminate_zeros()\n",
    "        intrsxn = rank_score_mat.multiply(bin_true_mat)\n",
    "        row_wise_overlap = intrsxn.getnnz(1)\n",
    "        if k in rK:\n",
    "            metrics[f'R@{k}'] = 100*(row_wise_overlap/bin_true_mat.getnnz(1)).mean()\n",
    "        if k in pK:\n",
    "            metrics[f'P@{k}'] = 100*row_wise_overlap.mean()/k\n",
    "            # intrsxn.data = 1 / np.log2(intrsxn.data + 1)\n",
    "            # ndcg_denom = np.cumsum(1 / np.log2(np.arange(k) + 2))[np.minimum(k-1, bin_true_mat.getnnz(1))]\n",
    "            # metrics[f'nDCG@{k}'] = 100*(np.array(intrsxn.sum(axis=1)).ravel()/ndcg_denom).mean()\n",
    "\n",
    "    metrics = pd.DataFrame(metrics, index=['Metrics']).round(2)\n",
    "    metrics = metrics.reindex(sorted(metrics.columns, key=lambda x: (x.split('@')[0], int(x.split('@')[1]))), axis=1)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <td>50.79</td>\n",
       "      <td>45.33</td>\n",
       "      <td>41.29</td>\n",
       "      <td>51.43</td>\n",
       "      <td>58.1</td>\n",
       "      <td>64.16</td>\n",
       "      <td>68.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           P@1    P@3    P@5   R@10  R@20   R@50  R@100\n",
       "Metrics  50.79  45.33  41.29  51.43  58.1  64.16  68.87"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_precision_recall(ranker_score_mat, data_manager.tst_X_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <td>48.73</td>\n",
       "      <td>43.85</td>\n",
       "      <td>40.03</td>\n",
       "      <td>50.26</td>\n",
       "      <td>57.6</td>\n",
       "      <td>64.58</td>\n",
       "      <td>68.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           P@1    P@3    P@5   R@10  R@20   R@50  R@100\n",
       "Metrics  48.73  43.85  40.03  50.26  57.6  64.58  68.87"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_precision_recall(score_mat, data_manager.tst_X_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@3\tP@5\tnDCG@1\tnDCG@3\tnDCG@5\tPSP@1\tPSP@3\tPSP@5\tR@10\tR@20\tR@50\tR@100\n",
      "50.56\t45.08\t41.08\t50.56\t47.74\t46.01\t30.19\t34.88\t39.2\t51.09\t57.7\t63.61\t67.76\n",
      "\n",
      "P@1 P@3 P@5 nDCG@1 nDCG@3 nDCG@5 PSP@1 PSP@3 PSP@5 R@10 R@20 R@50 R@100\n",
      "50.56 45.08 41.08 50.56 47.74 46.01 30.19 34.88 39.2 51.09 57.7 63.61 67.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compute_xmc_metrics(ranker_score_mat, data_manager.tst_X_Y, data_manager.inv_prop);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnz = trn_labels.getnnz(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_nnz_labels = np.where(nnz == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_loader.dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    11,    185,    437, ..., 669779, 669824, 669885])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_nnz_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "net = NETS[args.net](args)\n",
    "net.load(f'{args.OUT_DIR}/model.pt')\n",
    "net.to(args.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1901/1901 [02:48<00:00, 11.29it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.29it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 299/299 [00:49<00:00,  6.00it/s]\n",
      "Embedding: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1901/1901 [02:27<00:00, 12.91it/s]\n",
      "Embedding: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.96it/s]\n",
      "Embedding: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 299/299 [00:44<00:00,  6.78it/s]\n"
     ]
    }
   ],
   "source": [
    "trn_score_mat = unwrap(net).predict(trn_loader, K=args.eval_topk, accelerator=accelerator)\n",
    "val_score_mat = unwrap(net).predict(val_loader, K=args.eval_topk, accelerator=accelerator)\n",
    "tst_score_mat = unwrap(net).predict(tst_loader, K=args.eval_topk, accelerator=accelerator)\n",
    "\n",
    "trn_embs = unwrap(net).get_embs(trn_loader, accelerator=accelerator)\n",
    "val_embs = unwrap(net).get_embs(val_loader, accelerator=accelerator)\n",
    "tst_embs = unwrap(net).get_embs(tst_loader, accelerator=accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "trn_X_Xf, val_X_Xf, tst_X_Xf = data_manager.load_bow_fts(normalize=True)\n",
    "trn_ranker_embs = sp.hstack((normalize(trn_embs, copy=False), trn_X_Xf)).tocsr().astype(np.float32)\n",
    "val_ranker_embs = sp.hstack((normalize(val_embs, copy=False), val_X_Xf)).tocsr().astype(np.float32)\n",
    "tst_ranker_embs = sp.hstack((normalize(tst_embs, copy=False), tst_X_Xf)).tocsr().astype(np.float32)\n",
    "\n",
    "trn_labels = trn_loader.dataset.labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pecos.xmc import MLModel, MLProblem\n",
    "prob = MLProblem(trn_ranker_embs, trn_labels, C=sp.identity(trn_labels.shape[1]).tocsr(), M=trn_score_mat, R=None)\n",
    "mlm = MLModel.train(prob)\n",
    "mlm.pred_params.post_processor = 'l3-hinge'\n",
    "val_ranker_score_mat = mlm.predict(val_ranker_embs, csr_codes=val_score_mat.astype(np.float32), only_topk=val_score_mat.shape[1])    \n",
    "tst_ranker_score_mat = mlm.predict(tst_ranker_embs, csr_codes=tst_score_mat.astype(np.float32), only_topk=tst_score_mat.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <td>44.55</td>\n",
       "      <td>40.48</td>\n",
       "      <td>36.92</td>\n",
       "      <td>45.58</td>\n",
       "      <td>53.38</td>\n",
       "      <td>59.81</td>\n",
       "      <td>64.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           P@1    P@3    P@5   R@10   R@20   R@50  R@100\n",
       "Metrics  44.55  40.48  36.92  45.58  53.38  59.81  64.17"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_precision_recall(val_ranker_score_mat, val_loader.dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_inds = np.random.choice(np.arange(val_score_mat.shape[0]), size=min(5000, val_score_mat.shape[0]))\n",
    "nnz = trn_labels.getnnz(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "def get_tree_fts(smats, nnz, tmat = None, clf = None, mode='test'):\n",
    "    temp = smats[0].tocoo()\n",
    "    scores = []\n",
    "    for smat in smats:\n",
    "        scores.append(np.array(smat[temp.row, temp.col]).reshape(-1, 1))\n",
    "    scores.append(nnz[temp.col].reshape(-1, 1))\n",
    "    scores = np.hstack(scores)\n",
    "\n",
    "    if mode == 'train':\n",
    "        targets = np.array(tmat[temp.row, temp.col]).ravel()\n",
    "        return scores, targets\n",
    "    else:\n",
    "        res = smats[0].copy()\n",
    "        res[temp.row, temp.col] = clf.predict_proba(scores)[:, 1]\n",
    "        return res.tocsr()\n",
    "        \n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(\n",
    "        *get_tree_fts(\n",
    "            [val_ranker_score_mat, val_score_mat], \n",
    "            nnz=nnz,\n",
    "            tmat=val_loader.dataset.labels, \n",
    "            mode='train'\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_score_mat = get_tree_fts([val_ranker_score_mat, val_score_mat], nnz=nnz, clf=clf, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <td>46.52</td>\n",
       "      <td>42.06</td>\n",
       "      <td>38.14</td>\n",
       "      <td>46.54</td>\n",
       "      <td>53.98</td>\n",
       "      <td>60.68</td>\n",
       "      <td>64.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           P@1    P@3    P@5   R@10   R@20   R@50  R@100\n",
       "Metrics  46.52  42.06  38.14  46.54  53.98  60.68  64.17"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_precision_recall(tree_score_mat*0.5 + val_ranker_score_mat*0.5, val_loader.dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_score_mat = get_tree_fts([tst_ranker_score_mat, tst_score_mat], nnz=nnz, clf=clf, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <td>50.89</td>\n",
       "      <td>45.4</td>\n",
       "      <td>41.35</td>\n",
       "      <td>51.74</td>\n",
       "      <td>58.67</td>\n",
       "      <td>65.14</td>\n",
       "      <td>68.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           P@1   P@3    P@5   R@10   R@20   R@50  R@100\n",
       "Metrics  50.89  45.4  41.35  51.74  58.67  65.14  68.87"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_precision_recall(tree_score_mat*0.5 + tst_ranker_score_mat*0.5, tst_loader.dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_loader.dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_label_inds = np.where(nnz > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4000x3369 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 619 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[:, zero_nnz_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tst_ranker_score_mat = get_tree_fts([tst_ranker_score_mat], clf=clf, mode='test')*0.8 + tst_ranker_score_mat*0.2\n",
    "\n",
    "evaluator = XMCEvaluator(args, tst_loader, data_manager, prefix='tst_ranker')\n",
    "metrics = evaluator.eval(tst_ranker_score_mat)\n",
    "logging.info('\\n'+metrics.to_csv(sep='\\t', index=False))\n",
    "sp.save_npz(f'{args.OUT_DIR}/tst_ranker_score_mat.npz', tst_ranker_score_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe6fde4d3c3345dfd5f6b574b5e19f14d7f348afc60222df5d298419f564c554"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
